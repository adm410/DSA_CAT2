# Q1. With the aid of examples explain the rules of Big O notation in algorithm analysis.

Big O notation is a mathematical way to describe the efficiency of an algorithm in terms of time or space.
It provides an upper bound on the running time of an algorithm as a function of the input size, ensuring that we can understand how the algorithm will scale as the input grows.

### Key Rules of Big O Notation:
1. Focus on the highest order term:
- Only the term that grows the fastest with the input size matters, smaller terms become insignificant for larger inputs.
- <ins>Example:</ins><br>
    The time complexity is $O(n^2 + n)$, the $n^2$ term dominates as $n$ grows larger, then the complexity simplifies to $O(n^2)$.

2. Combining like terms:
- If there are multiple terms you combine them and keep the term that grows the fastest with increasing input size.
- <ins>Example:</ins><br>
    An algorithm with time complexity $O(n^3 + n^2 + n)$ will simplify to $O(n^3)$ because the $n^3$ term dominates for large $n$.

3. Drop constant factors:
- Constant factors are ignored because they don’t affect the growth rate.
- <ins>Example:</ins><br>
    If an algorithm runs for $O(3n)$ time, we can simplify it to $O(n)$ because the constant 3 doesn't affect the growth rate.

4. Nested loops:
- The time complexity is the product of the sizes of the loops.
- <ins>Example:</ins><br>
    For an algorithm with two nested loops, each running from 1 to $n$, the time complexity is $O(n×n) = O(n^2)$.

5. Different growth rates:
- Big O notations has many different growth rates:
    - $O(1)$- Constant time, the algorithm runs in the same time regardless of input size.
    - $O(n)$- Linear time, the time grows directly in proportion to the input size.
    - $O(n^2)$- Quadratic time, the time grows proportionally to the square of the input size, often seen with nested loops.
    - $O(\log n)$- Logarithmic time, the time grows slowly as the input size increases.